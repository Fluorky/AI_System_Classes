# -*- coding: utf-8 -*-
"""SystemyAI_lab_6_zad4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pHD3SoKq406iVm00BZ7ANrWyOPJsHEnN

Import biblioteki **TensorFlow** ([https://www.tensorflow.org/](https://www.tensorflow.org/)) z której będziemy korzystali w **uczeniu maszynowym**:
"""

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np

x_point = []
y_point = []

x_point = [2, 2, 0, -2, -2, 0, 4]
y_point= [1, 2, 6, 10, 0, 0, -20]
d = [1, 1, 1, -1, -1, -1, -1]

sd = [1, 1, 1, 0, 0, 0, 0]



plt.scatter(x_point,y_point,c='b')
plt.show()

real_x = np.array(x_point)
real_y = np.array(y_point)

import keras
from keras.models import Sequential
from keras.layers import Dense

"""Definiujemy model:"""

model = Sequential()

"""Dodajemy **jedną warstwę** (Dense) z **jednym neuronem** (units=1) z **biasem** (use_bias=True) i **liniową funkcją aktywacji** (activation="linear"):"""

model.add(Dense(units = 1, use_bias=True, input_dim=2, activation = "sigmoid"))

"""Definiujemy **optymalizator** i **błąd** (średni błąd kwadratowy - MSE). **Współczynnik uczenia = 0.1**"""

opt = tf.keras.optimizers.SGD(learning_rate=0.1)

model.compile(loss='BinaryCrossentropy',optimizer=opt)

model.summary()

"""Proces **uczenia**:"""

data = np.column_stack((real_x,real_y))
data_train = np.asarray(data)

d_train = np.asarray(sd)

print(data_train)

epochs = 6000
h = model.fit(data_train,d_train, verbose=1, epochs=epochs, batch_size=5)

Loss = h.history['loss']
Loss

"""Sprawdźmy jakie są **wartości wag**:"""

weights = model.get_weights()

print(weights[0][0][0])
print(weights[1][0])    #bias

plt.scatter(np.arange(epochs),Loss)
plt.show()

"""Sprawdzenie **modelu**:"""

#model.predict([0.6])

model.predict(data_train)

X = np.linspace(min, max, num=10)
plt.plot(X,(weights[0][0][0])*X+(weights[1][0]),c='r')
plt.scatter(x_point,y_point,c='b')
plt.show()

